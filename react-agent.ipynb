{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/llm/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "# settings\n",
    "import GPUtil\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.mistralai import MistralAI\n",
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from pathlib import Path\n",
    "from utils import get_doc_tools\n",
    "from loguru import logger\n",
    "\n",
    "device = \"cuda\" if len(GPUtil.getAvailable()) >= 1 else \"cpu\"\n",
    "\n",
    "llm = MistralAI(\n",
    "    api_key=\"jiSxvwweunDg9qY8LasnngBrqPVaPMGb\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\", device=device\n",
    ")\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting tools for source: ./data/COT.csv\n",
      "Getting tools for source: ./data/ANZ.pdf\n",
      "ToolMetadata(description='Useful if you want to get a summary of Coach On Tap platform.', name='cot_summary_tool', fn_schema=<class 'llama_index.core.tools.types.DefaultToolFnSchema'>, return_direct=False)\n",
      "ToolMetadata(description='A RAG engine with some facts about Coach On Tap platform.', name='cot_qna_tool', fn_schema=<class 'llama_index.core.tools.types.DefaultToolFnSchema'>, return_direct=False)\n",
      "ToolMetadata(description='Useful if you want to get a summary of ANZ Bank.', name='anz_summary_tool', fn_schema=<class 'llama_index.core.tools.types.DefaultToolFnSchema'>, return_direct=False)\n",
      "ToolMetadata(description='A RAG engine with some facts about ANZ Bank.', name='anz_qna_tool', fn_schema=<class 'llama_index.core.tools.types.DefaultToolFnSchema'>, return_direct=False)\n"
     ]
    }
   ],
   "source": [
    "sources = [\n",
    "    (\"./data/COT.csv\", \"Coach On Tap platform\"),\n",
    "    (\"./data/ANZ.pdf\", \"ANZ Bank\"),\n",
    "]\n",
    "source_to_tools_dict = {}\n",
    "for source, desc in sources:\n",
    "    print(f\"Getting tools for source: {source}\")\n",
    "    vector_tool, summary_tool = get_doc_tools(source, Path(source).stem, desc)\n",
    "    source_to_tools_dict[source] = [vector_tool, summary_tool]\n",
    "\n",
    "# Create all tools\n",
    "all_tools = [t for s, _ in sources for t in source_to_tools_dict[s]]\n",
    "for i in all_tools:\n",
    "    print(i.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReActAgent.from_tools(all_tools, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object ReActAgentWorker._add_back_chunk_to_stream.<locals>.gen at 0x31c4efc60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_response = agent.stream_chat(\n",
    "    \"Calculate sum of the coaching platform's profit in 3 months. Each month platform earns 2$\"\n",
    ")\n",
    "\n",
    "stream_response.chat_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.chat(\n",
    "    \"How do I know whether my ANZ Digital Key is setup to receive notifications or to use a QRcode?\"\n",
    ")\n",
    "\n",
    "print(response)\n",
    "logger.info(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.chat(\n",
    "    \"Give me summary of ANZ DK\"\n",
    ")\n",
    "\n",
    "print(response)\n",
    "logger.info(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
